# Lv9+.2. 寄存器分配

你可能已经发现了, 即使输入的程序很简单, 你的编译器也经常会生成大量的代码, 而且大部分都是 load/store.

还记得这些 load/store 是怎么产生的吗? 在 [Lv4.2](/lv4-const-n-var/var-n-assign) 中, 你第一次处理了 SysY 中变量的目标代码生成, 并且意识到: 把 SysY 中的变量, 以及编译器生成的计算过程中所有的中间结果都保存在 CPU 的寄存器里, 是很不现实的, 因为寄存器的数量太少了. 要想提高生成代码的质量, 你的编译器就必须可以尽可能利用寄存器, 把那些对性能至关重要的内容保留在寄存器上, 把那些实在放不进寄存器的内容保存在内存中.

于是, 你便开始找寻, 那些散落在世间的, 传说中的[寄存器分配算法](https://en.wikipedia.org/wiki/Register_allocation).

## 不分配寄存器

在之前的章节中, 我们讲述的都是这种策略. 也就是: 把所有变量都放在内存里.

它的好处是实现简单, 坏处也显而易见: 完全没用到寄存器, 进而导致编译器生成的代码性能过低.

## 分配, 但没完全分配

另一种简单的寄存器分配策略是: 遇到一个需要被分配的变量, 就从寄存器列表里找出一个没被占用的寄存器, 把它分配个这个变量. 如果所有能用的寄存器都已经被占用了, 再退化到不分配寄存器的策略.

这种策略的特点是: 虽然编译器还是没搞懂到底怎么分配寄存器, 但它觉得直接躺平也太没面子了, 于是简单挣扎了一下. 这种策略只比不分配的策略复杂了一点点, 总体来说它的实现还是相当简单的. 并且如果很走运, 你的编译器处理的函数都比较短, 那这种方法也能产生性能表现不错的代码.

另外, 一旦你开始为变量分配寄存器, 你就必须注意 ABI/调用约定导致的寄存器生命周期的问题. 比如对于如下 Koopa IR:

```koopa
%0 = add 1, 1
%1 = call @func()
%2 = add %0, %1
```

我们先定义了 `%0`, 然后进行了一次函数调用, 最后才使用了 `%0`. 但 ABI 规定, 某些寄存器是 “caller-saved” 的, 某些是 “callee-saved” 的. 如果你把 `%0` 放在了 “caller-saved” 寄存器中, 那你就必须在调用函数 `@func` 前保存这个寄存器的内容, 否则 `%0` 定义时保存的结果就会丢失. 而如果你把 `%0` 放在了 “callee-saved” 寄存器中, 你就必须在进入函数之前先保存这个寄存器原有的内容, 退出函数之前再将其恢复.

## 把寄存器当缓存用

基于前一种策略, 我们还能扩展出很多其他的寄存器分配方法, 比如其中一种——把寄存器当缓存用:

1. 首先, 在栈帧上为所有变量都分配空间.
2. 当需要用到某个变量的时候, 把这个变量读出来, 放在一个临时分配的寄存器里.
3. 下次需要读写变量时, 直接操作寄存器的值, 省去内存访问的开销.
4. 如果遇到某些情况, 比如出现了函数调用, 或者发生了控制流转移, 就把寄存器里保存的所有变量写回栈帧, 下次用的时候再重新读取.

?> **思考:** 为什么需要做第 4 点?

这种方法把寄存器的生命周期局限在了基本块内, 是一种局部 (local) 的寄存器分配策略. 在编译技术的语境下, 我们通常把那些基本块级别的算法称为 “局部” 的算法, 把函数级别的算法称为 “全局” (global) 的算法, 而把程序级别的算法称为 “过程间” (interprocedural) 的算法. 这和大家所理解的, 编程语言角度上的 “全局” 和 “局部”, 还是有很大区别的.

关于更多 on-the-fly 的寄存器分配策略, 你可以参考 R 大 (RednaxelaFX) 的这篇知乎回答: [寄存器分配问题?](https://www.zhihu.com/question/29355187/answer/51935409). R 大曾经在知乎上回答过大量编译技术, 编程语言和高级语言虚拟机方向的问题, 但很可惜他现在已经不上知乎了. 如果你对以上这些话题感兴趣, 十分推荐你去翻一翻 R 大的回答和文章列表.

## 活跃变量分析

你有没有觉得, 我们介绍的前几个寄存器分配策略, 都有些太过 “小心翼翼” 了?

* 要么把所有的寄存器都看成一次性用品, 分完了就完了, 转头去用内存.
* 要么一出基本块, 就把所有分好的寄存器写回内存.

难道就不能检测一下, 一旦某个变量在之后的程序里再也不会被用到了, 我们就把分给它的寄存器拿来, 然后重新分给别的变量用吗?

太对了! 如果真的能做到这件事, 那寄存器就可以被及时复用, 变量会有更多的机会被分配到寄存器上. 可问题的关键是: 我们应该怎么检测, 某个变量在之后的程序中还有没有用——或者说, 检测某个变量的生命周期呢?

你可能会说: 这事简单! 我扫一遍 IR, 给每条指令编个号, 再每个变量都分一个 `pair`, 记一下它最早什么时候出现, 最晚什么时候出现, 扫描的时候更新一下最晚出现的那个变量, 这不就完事了吗? 比如下面这段 Koopa IR 程序:

```koopa
%bb:
  %x = load %a
  %y = add %x, 1
  %z = add %x, 2
  %p = add %z, 3
```

很明显, `%x` 的生命周期是第一条指令到第三条指令, `%z` 的生命周期是第三条指令到第四条, `%a`, `%y` 和 `%p` 的生命周期只在它们对应的那条指令之内. 于是, 我们可以把 `%a`, `%x`, `%z` 和 `%p` 都分配到同一个寄存器上, 然后给 `%y` 分配另一个寄存器.

看起来很美好, 是吗? 那如果我加一条指令:

```koopa
%bb:
  %x = load %a
  %y = add %x, 1
  %z = add %x, 2
  %p = add %z, 3
  jump %bb
```

先别管这个程序是不是死循环, 只看变量的生命周期: 之前的那个方法已经不起作用了, 因为虽然变量 `%a` 在线性展开的 IR 指令序列中再没出现过, 但由于 `jump` 指令的存在, 在控制流图中, `%a` 的生命周期并没有在第一条指令之后结束.

假如我们给 `%a`, `%x`, `%z`, `%p` 都分配了相同的寄存器, 显然 `%a` 的值会被后续变量覆盖掉. 一旦进入下一次循环, `load %a` 所得到的就会是一个错误的值. 此后, 整个程序都乱成了一锅粥.

所以, 检测变量的生命周期, 并不是一个简单的事情——至少不像看起来那么简单. 在编译技术中, 有一种专门用来做这件事的算法: 活跃变量分析 ([live-variable analysis](https://en.wikipedia.org/wiki/Live_variable_analysis)) 算法.

活跃变量分析是一种数据流分析 ([data-flow analysis](https://en.wikipedia.org/wiki/Data-flow_analysis)) 算法, 顾名思义, 这种算法分析的是程序中数据的流动. 数据流分析算法运行时, 会在程序的控制流图上不断迭代, 根据图中的节点和某些其他规则, 求解数据流方程, 直到收敛到不动点. 说人话就是, 这类算法本质上都由一个大循环构成, 里面遍历 CFG 并做一些计算, 如果计算的结果不再变化, 就退出循环, 然后把计算结果视为算法的运行结果.

关于活跃变量分析的具体介绍和实现, 你可以参考 *Engineering a Compiler 2nd Edition* 一书的 8.6.1 节和 9.2.2 节, 或者自行 STFW, 此处不再赘述.

## 线性扫描寄存器分配

基于活跃变量分析的结果, 我们就可以实现更多更有效的寄存器分配算法了, 线性扫描寄存器分配 ([linear scan register allocation](https://en.wikipedia.org/wiki/Register_allocation#Linear_scan), LSRA) 就是其中之一.

线性扫描, 顾名思义, 是一个线性的寄存器分配算法. 它需要按顺序扫描变量的活跃区间, 然后基于一些贪婪的策略, 把变量放在寄存器上或者栈上. 因为这种算法只需要进行一次扫描, 就可以得到很不错的寄存器分配结果, 所以它经常被用在某些很看重编译效率的场合中, 比如即时编译 ([just-in-time compilation](https://en.wikipedia.org/wiki/Just-in-time_compilation), JIT).

关于线性扫描的详细介绍和实现, 你可以参考论文: [*Poletto & Sarkar 1999, "Linear scan register allocation"*](https://doi.org/10.1145%2F330249.330250).

## 图着色寄存器分配

另一种广为使用的寄存器分配算法是图着色分配 ([graph-coloring allocation](https://en.wikipedia.org/wiki/Register_allocation#Graph-coloring_allocation)) 算法. 这种算法相比 LSRA 要更为重量级, 运行起来更为耗时, 实现起来也更加复杂, 但通常情况下可以达到更好的寄存器分配结果.

图着色寄存器分配的思路很简单, 就是把寄存器问题映射到[图着色问题](https://en.wikipedia.org/wiki/Graph_coloring)上: 如果两个变量的生命周期相互重叠, 那么它们就不能被放在相同的寄存器上. 于是我们可以给所有变量建个图 (学名叫 interference graph), 图的顶点代表变量. 如果两个变量的生命周期重叠, 这两个变量代表的顶点之间就连一条边.

寄存器分配的过程, 本质上就是把 $N$ 个寄存器当作 $N$ 种颜色, 然后给这个图着色, 确保两个相邻顶点的颜色不同. 如果算法运行时发现这件事情做不到, 它就会从中删掉一些顶点, 代表把这些顶点对应的变量 spill 到栈上, 然后重新着色, 直到着色完成为止.

关于图着色的详细介绍和实现, 你可以参考论文: [*Chaitin 1982, "Register allocation & spilling via graph coloring"*](https://doi.org/10.1145%2F800230.806984).

?> 寄存器分配算法的分配结果的确取决于算法本身, 但你并不能只通过编译器使用了 LSRA 还是图着色, 就断定编译器的寄存器分配结果是绝对的好或坏.
<br><br>
LSRA 和图着色在实现上都有很多细节可以打磨. 比如, 在寄存器数量不足时, 你可以选择 spill 某些变量到栈上, 把另外的变量放入寄存器. 这个 “选择在寄存器中保留哪些变量” 的策略, 本身就可以做得很复杂. 你可以考虑很多东西: 变量的生命周期长短如何? 变量被使用的频率是高是低? 变量是否位于很多层循环之中? 等等. 一个实现的很好的 LSRA, 在分配结果上, 可能和一个实现不怎么好的 LSRA 有着天壤之别.
<br><br>
LLVM 所主要使用的寄存器分配策略 ([Greedy](https://github.com/llvm/llvm-project/blob/main/llvm/lib/CodeGen/RegAllocGreedy.cpp)), 即是 LSRA 的一个变种: [Greedy Linear Scan](https://blog.llvm.org/2011/09/greedy-register-allocation-in-llvm-30.html), 其分配结果的质量已经足够高了.
